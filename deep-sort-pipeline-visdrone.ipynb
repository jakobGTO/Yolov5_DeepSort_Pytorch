{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e4ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix VisDrone mot labels\n",
    "# TODO: Fix ConservationDrones mot labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8c1759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import motmetrics as mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b62c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving split: test-dev\n",
      "Solving split: train\n",
      "Solving split: val\n"
     ]
    }
   ],
   "source": [
    "%run -i visdrone-to-MOT.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7cc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the specific tracker, edit which model and which sequences to evaluate within the file\n",
    "# The evaluated sequence files lies in the evaluated_sequences folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to use your own re-id model:\n",
    "# Train it using torchreid, place the model in Yolov5_DeepSort_Pytorch/deep_sort/deep/checkpoint/model_name.pth\n",
    "# Also add it to trained_urls in Yolov5_DeepSort_Pytorch/deep_sort/deep/reid_model_factory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d590043",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2bedba18932b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdeep_sort_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'resnet50_jakob'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msequences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:/thesis-data/VisDrone2019-MOT-test-dev/sequences'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluated_sequences'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluated_sequences'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = 'D:/thesis-data/VisDrone2019-MOT-test-dev/sequences/'\n",
    "yolo_model = 'best.pt'\n",
    "deep_sort_model = 'resnet50_jakob'\n",
    "\n",
    "sequences = os.listdir('D:/thesis-data/VisDrone2019-MOT-test-dev/sequences')\n",
    "shutil.rmtree('evaluated_sequences')\n",
    "os.mkdir('evaluated_sequences')\n",
    "\n",
    "# loop across all test sequences\n",
    "for seq in sequences:\n",
    "    childproc = subprocess.Popen('python track.py --source ' + data_dir + seq + \\\n",
    "                                 ' --yolo_model ' + yolo_model + \\\n",
    "                                 ' --deep_sort_model ' + deep_sort_model + \\\n",
    "                                 ' --project evaluated_sequences/ --name \"sequence\" --save-txt')\n",
    "    childproc.wait()\n",
    "    shutil.move(\"evaluated_sequences/sequence/\" + str(seq) + \".txt\",\n",
    "                \"evaluated_sequences/\")\n",
    "    shutil.rmtree(\"evaluated_sequences/sequence\")\n",
    "    pred = np.loadtxt(\"evaluated_sequences/\" + seq + \".txt\", dtype=int)\n",
    "    np.savetxt(\"evaluated_sequences/\" + seq + \".txt\", pred.astype(float), fmt ='%.0f', delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec760f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i evaluate_tracker.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f325774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MOT metrics for evaluated trackers\n",
    "\n",
    "# Fix structure of dataset in TrackEval/data/mot_challenge/gt and trackers according to \n",
    "# https://github.com/JonathonLuiten/TrackEval/tree/master/docs/MOTChallenge-Official\n",
    "# example in /gt/visdrone-train and /trackers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46cf7ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : False                         \n",
      "NUM_PARALLEL_CORES   : 8                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : C:\\Users\\Jakob\\OneDrive\\Skrivbord\\Github\\Thesis-2022\\deep-sort\\TrackEval\\error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : False                         \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "PRINT_CONFIG         : True                          \n",
      "GT_FOLDER            : C:\\Users\\Jakob\\OneDrive\\Skrivbord\\Github\\Thesis-2022\\deep-sort\\TrackEval\\data/gt/mot_challenge/\n",
      "TRACKERS_FOLDER      : C:\\Users\\Jakob\\OneDrive\\Skrivbord\\Github\\Thesis-2022\\deep-sort\\TrackEval\\data/trackers/mot_challenge/\n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : None                          \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : visdrone                      \n",
      "SPLIT_TO_EVAL        : train                         \n",
      "INPUT_AS_ZIP         : False                         \n",
      "DO_PREPROC           : False                         \n",
      "TRACKER_SUB_FOLDER   : data                          \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : None                          \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt.txt   \n",
      "SKIP_SPLIT_FOL       : False                         \n",
      "C:\\Users\\Jakob\\OneDrive\\Skrivbord\\Github\\Thesis-2022\\deep-sort\\TrackEval\\data/gt/mot_challenge/visdrone-train\\seq1\\seqinfo.ini\n",
      "C:\\Users\\Jakob\\OneDrive\\Skrivbord\\Github\\Thesis-2022\\deep-sort\\TrackEval\\data/trackers/mot_challenge/visdrone-train\\seq1\\data\\seq1.txt\n",
      "\n",
      "CLEAR Config:\n",
      "METRICS              : ['HOTA', 'CLEAR', 'Identity'] \n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n",
      "\n",
      "Identity Config:\n",
      "METRICS              : ['HOTA', 'CLEAR', 'Identity'] \n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n",
      "\n",
      "Evaluating 1 tracker(s) on 1 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, CLEAR, Identity, Count\n",
      "\n",
      "\n",
      "Evaluating seq1\n",
      "\n",
      "    MotChallenge2DBox.get_raw_seq_data(seq1, seq1)                         0.7726 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                1.0666 sec\n",
      "    HOTA.eval_sequence()                                                   0.6019 sec\n",
      "    CLEAR.eval_sequence()                                                  0.0334 sec\n",
      "    Identity.eval_sequence()                                               0.1417 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "1 eval_sequence(seq1, seq1)                                              2.6471 sec\n",
      "\n",
      "All sequences for seq1 finished in 2.65 seconds\n",
      "\n",
      "HOTA: seq1-pedestrian              HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      RHOTA     HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "seq1                               19.485    26.959    14.787    34.621    45.279    22.72     22.612    72.347    22.269    30.431    57.885    17.615    \n",
      "COMBINED                           19.485    26.959    14.787    34.621    45.279    22.72     22.612    72.347    22.269    30.431    57.885    17.615    \n",
      "\n",
      "CLEAR: seq1-pedestrian             MOTA      MOTP      MODA      CLR_Re    CLR_Pr    MTR       PTR       MLR       sMOTA     CLR_TP    CLR_FN    CLR_FP    IDSW      MT        PT        ML        Frag      \n",
      "seq1                               5.7085    69.13     12.025    44.243    57.863    13.592    56.311    30.097    -7.9491   6332      7980      4611      904       14        58        31        1110      \n",
      "COMBINED                           5.7085    69.13     12.025    44.243    57.863    13.592    56.311    30.097    -7.9491   6332      7980      4611      904       14        58        31        1110      \n",
      "\n",
      "Identity: seq1-pedestrian          IDF1      IDR       IDP       IDTP      IDFN      IDFP      \n",
      "seq1                               22.657    19.99     26.145    2861      11451     8082      \n",
      "COMBINED                           22.657    19.99     26.145    2861      11451     8082      \n",
      "\n",
      "Count: seq1-pedestrian             Dets      GT_Dets   IDs       GT_IDs    \n",
      "seq1                               10943     14312     73        103       \n",
      "COMBINED                           10943     14312     73        103       \n",
      "\n",
      "Timing analysis:\n",
      "MotChallenge2DBox.get_raw_seq_data                                     0.7726 sec\n",
      "MotChallenge2DBox.get_preprocessed_seq_data                            1.0666 sec\n",
      "HOTA.eval_sequence                                                     0.6019 sec\n",
      "CLEAR.eval_sequence                                                    0.0334 sec\n",
      "Identity.eval_sequence                                                 0.1417 sec\n",
      "Count.eval_sequence                                                    0.0000 sec\n",
      "eval_sequence                                                          2.6471 sec\n",
      "Evaluator.evaluate                                                     3.0042 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i ../TrackEval/scripts/run_mot_challenge.py --BENCHMARK visdrone --DO_PREPROC False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
